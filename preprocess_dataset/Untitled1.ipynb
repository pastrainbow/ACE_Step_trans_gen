{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7929df1-322a-4f0d-ac42-63e36e22cd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.057142857142857\n",
      "20.057142857142857\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "def noise_gen_gaussian_stereo(range_factor, frame_count, device):\n",
    "    mean = 0.0\n",
    "    #portion of values in range = 1 - 1 / range_factor^2\n",
    "    #value range is 1 here\n",
    "    std = 1.0 / range_factor\n",
    "    \n",
    "    # Gaussian noise: create a random normal distribution that has the same size as the data to add noise to \n",
    "    # Genearte noise with same size as that of the data.\n",
    "    ch_1 = torch.normal(mean=mean, std=std, size=(frame_count,), device=device)\n",
    "    ch_2 = torch.normal(mean=mean, std=std, size=(frame_count,), device=device)\n",
    "    return torch.stack((ch_1, ch_2))\n",
    "\n",
    "\n",
    "def load_audio(path, sample_rate=44100):\n",
    "    audio, sr = torchaudio.load(path)\n",
    "    # Resample if needed\n",
    "    if sr != sample_rate:\n",
    "        resampler = Resample(orig_freq=sr, new_freq=sample_rate)\n",
    "        audio = resampler(audio)\n",
    "    return audio\n",
    "\n",
    "def prompts_concat(start_audio_path, end_audio_path, output_path, noise_duration, device, sample_rate=44100):\n",
    "    range_factor = 4  # for gaussian noise generation\n",
    "\n",
    "    start_audio_data = load_audio(start_audio_path, sample_rate).to(device)\n",
    "    end_audio_data = load_audio(end_audio_path, sample_rate).to(device)\n",
    "    \n",
    "    noise_data = noise_gen_gaussian_stereo(\n",
    "        range_factor,\n",
    "        int(noise_duration * sample_rate),\n",
    "        device,\n",
    "    )\n",
    "    concat_data = torch.cat((start_audio_data, noise_data, end_audio_data), dim=1)\n",
    "    # print(concat_data.shape)\n",
    "    torchaudio.save(output_path, concat_data, sample_rate)\n",
    "\n",
    "    #since we had already loaded the start and end tracks, we can also get the repaint start and end times here\n",
    "    start_audio_duration = start_audio_data.shape[-1] / sample_rate\n",
    "    return (start_audio_duration, start_audio_duration + noise_duration)\n",
    "\n",
    "\n",
    "start_audio_path = \"/homes/al4624/Documents/YuE_finetune/inference_audio_prompts/start.mp3\"\n",
    "end_audio_path = \"/homes/al4624/Documents/YuE_finetune/inference_audio_prompts/end.mp3\"\n",
    "output_path = \"/homes/al4624/Documents/YuE_finetune/inference_audio_prompts/full.mp3\"\n",
    "\n",
    "device = torch.device(f\"cuda:{cuda_idx}\" if torch.cuda.is_available() else \"cpu\")\n",
    "start, end = prompts_concat(start_audio_path, end_audio_path, output_path, 10, device)\n",
    "print(start)\n",
    "print(end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ace_step)",
   "language": "python",
   "name": "ace_step"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
